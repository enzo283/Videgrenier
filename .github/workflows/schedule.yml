name: weekly-scrape

on:
  schedule:
    - cron: '0 6 * * 1'
  workflow_dispatch:

jobs:
  debug-scrape:
    runs-on: ubuntu-latest
    env:
      SOURCE_URL: ${{ secrets.SOURCE_URL }}
      DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run scraper and save output
        run: |
          mkdir -p /tmp/scrape-debug
          LOG=/tmp/scrape-debug/scrape-debug.txt
          echo "=== START $(date -u) ===" >"$LOG"
          echo "SOURCE_URL='${SOURCE_URL}'" >>"$LOG"
          echo "DISCORD_WEBHOOK_SET='${DISCORD_WEBHOOK:+yes}'" >>"$LOG"
          echo "" >>"$LOG"
          echo "=== CURL HEAD ===" >>"$LOG"
          curl -I --fail --location --max-time 15 "${SOURCE_URL}" >>"$LOG" 2>&1 || echo "curl HEAD failed" >>"$LOG"
          echo "" >>"$LOG"
          echo "=== CURL FIRST LINES (HTML) ===" >>"$LOG"
          curl --fail --location --max-time 15 "${SOURCE_URL}" -s | sed -n '1,200p' >>"$LOG" 2>&1 || echo "curl show failed" >>"$LOG"
          echo "" >>"$LOG"
          echo "=== RUN bot/main.py ===" >>"$LOG"
          if [ -f bot/main.py ]; then
            python -u bot/main.py >>"$LOG" 2>&1 || echo "python script exited with non-zero" >>"$LOG"
          else
            echo "bot/main.py NOT FOUND" >>"$LOG"
          fi
          echo "" >>"$LOG"
          echo "=== END $(date -u) ===" >>"$LOG"
          echo "WROTE LOG TO $LOG"
        shell: bash

      - name: Upload debug log artifact
        uses: actions/upload-artifact@v4
        with:
          name: scrape-debug
          path: /tmp/scrape-debug/scrape-debug.txt
